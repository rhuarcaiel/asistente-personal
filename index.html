<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mi Asistente Personal</title>
    <script src="https://accounts.google.com/gsi/client" async defer></script>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; background-color: #f0f0f0; }
        button { padding: 15px 30px; font-size: 1em; cursor: pointer; border-radius: 10px; border: none; background-color: #007bff; color: white; margin: 5px; }
        #botonGoogle { background-color: #4285F4; }
        #resultado { margin-top: 20px; padding: 15px; border: 1px solid #ccc; border-radius: 5px; background-color: white; min-height: 50px; width: 80%; max-width: 400px; text-align: center; white-space: pre-line; }
        .hidden { display: none; }
    </style>
</head>
<body>
    <h1>Mi Asistente Personal</h1>
    <div id="auth-section">
        <p>Para acceder a tu calendario, inicia sesión:</p>
        <div id="botonGoogle">
            <button id="googleLoginBtn">Iniciar sesión con Google Calendar</button>
        </div>
    </div>
    <div id="app-section" class="hidden">
        <button id="botonHablar">🎤 Hablar</button>
        <div id="resultado">Di algo...</div>
    </div>

    <script>
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) { alert('Tu navegador no soporta la API de voz. Prueba en Chrome.'); }

        const recognition = new SpeechRecognition();
        recognition.lang = "es-ES";
        recognition.interimResults = false;

        const botonHablar = document.getElementById('botonHablar');
        const resultado = document.getElementById('resultado');
        const authSection = document.getElementById('auth-section');
        const appSection = document.getElementById('app-section');

        const GOOGLE_CLIENT_ID = '730540890311-2n0tj0q7f5dp3v8j6h16n1rmkjqt8m98.apps.googleusercontent.com';
        const BACKEND_URL = 'https://asistente-personal-eta.vercel.app';
        let accessToken = ''; // Variable global para guardar el token

        // === Nuevo flujo OAuth 2.0 con scopes (La solución de tu amigo) ===
        function iniciarSesionConGoogle() {
            const client = google.accounts.oauth2.initTokenClient({
                client_id: GOOGLE_CLIENT_ID,
                scope: 'https://www.googleapis.com/auth/calendar https://www.googleapis.com/auth/userinfo.email',
                callback: async (tokenResponse) => {
                    console.log('Access token recibido:', tokenResponse.access_token);
                    accessToken = tokenResponse.access_token; // Guardamos el token

                    const res = await fetch(`${BACKEND_URL}/api/procesar-ia`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ access_token: tokenResponse.access_token })
                    });

                    const data = await res.json();
                    if (data.message) {
                        authSection.classList.add('hidden');
                        appSection.classList.remove('hidden');
                        resultado.textContent = `Acceso concedido a Calendar para ${data.user}`;
                    } else {
                        resultado.textContent = 'Error al iniciar sesión con Google Calendar: ' + data.error;
                    }
                }
            });
            client.requestAccessToken();
        }

        window.onload = () => {
            document.getElementById('googleLoginBtn').onclick = iniciarSesionConGoogle;
        };
        
        // --- Lógica del Asistente de Voz (sin cambios) ---
        botonHablar.addEventListener('click', () => {
            recognition.start();
            botonHablar.textContent = '🔴 Escuchando...';
            resultado.textContent = 'Estoy escuchando...';
        });

        recognition.onresult = async (event) => {
            const transcript = event.results[0][0].transcript;
            resultado.textContent = `Has dicho: "${transcript}".\n\nProcesando con IA...`;
            botonHablar.textContent = '🎤 Hablar';

            try {
                const response = await fetch(`${BACKEND_URL}/api/procesar-ia`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ userText: transcript }),
                });
                const data = await response.json();
                resultado.textContent = `Acción: ${data.accion}\nTarea: ${data.tarea}\nFecha: ${data.fecha || 'No especificada'}\nHora: ${data.hora || 'No especificada'}`;
            } catch (error) {
                console.error('Error al contactar la IA:', error);
                resultado.textContent = 'Error al procesar la solicitud. Revisa la consola.';
            }
        };

        recognition.onerror = (event) => {
            resultado.textContent = `Error de voz: ${event.error}`;
            botonHablar.textContent = '🎤 Hablar';
        };
    </script>
</body>
</html>


